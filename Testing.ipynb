{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pulp as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class karmbandit:\n",
    "    \"\"\"This is the k arm bandit problem\n",
    "\n",
    "    Attributes:\n",
    "        d: number of arms\n",
    "        distribution (str): distribution of rewards\n",
    "        params (array): parameters of the distribution, the line i contain the parameters of the distribution of the arm i\n",
    "        best_arm (int): index of the best arm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d, distribution, params):\n",
    "        \"\"\"Init the k arm bandit problem\n",
    "\n",
    "        Args:\n",
    "            d (int): number of arms\n",
    "            distribution (str): distribution of rewards\n",
    "            params (array): parameters of the distribution, the line i contain the parameters of the distribution of the arm i\n",
    "        \"\"\"\n",
    "\n",
    "        self.d = d\n",
    "        self.distribution = distribution\n",
    "        if distribution == 'bernoulli':\n",
    "            self.mus = params\n",
    "        if distribution == 'gaussian':\n",
    "            self.mus = params[:,0]\n",
    "            self.sigmas = params[:,1]\n",
    "        \n",
    "        self.best_arm = np.argmax(self.mu)\n",
    "\n",
    "    def pull(self, index):\n",
    "        \"\"\"Pull the arm index\n",
    "        \n",
    "        Args:\n",
    "            index (int): index of the arm to pull\n",
    "            \n",
    "        Returns:\n",
    "            reward (float): reward of the arm\n",
    "        \"\"\"\n",
    "\n",
    "        if self.distribution == 'bernoulli':\n",
    "            return np.random.bernoulli(self.mu[index])\n",
    "        if self.distribution == 'gaussian':\n",
    "            return np.random.normal(self.mu[index], self.sigma[index])\n",
    "\n",
    "class karmpolicy:\n",
    "    \"\"\"This is the k arm bandit policy\n",
    "\n",
    "    Attributes:\n",
    "        d: number of arms\n",
    "        self.muhat (array): empiric mean of the arms\n",
    "        t (int): time step\n",
    "        w (array): number of time an arm is played\n",
    "        regrets (list) : regret at each time step\n",
    "        policy (str): policy to use\n",
    "        params (array): parameters of the policy\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, karmbandit, policy, algoparams , prior = \"uniform\"):\n",
    "        \"\"\"Init the k arm bandit policy\n",
    "\n",
    "        Args:\n",
    "            d (int): number of arms\n",
    "            policy (str): policy to use\n",
    "            algoparams (array): parameters of the policy, c for ucb, epsilon for epsilon-greedy, param of the prior for thompson sampling\n",
    "            prior (str): by default it is the uniform prior\n",
    "        \"\"\"\n",
    "        # get the parameters of the k arm bandit problem\n",
    "        self.karmbandit = karmbandit\n",
    "        self.d = karmbandit.d\n",
    "        self.bestarm = karmbandit.best_arm\n",
    "        self.mus = karmbandit.mu\n",
    "        self.sigmas = karmbandit.sigma\n",
    "        self.distribution = karmbandit.distribution\n",
    "        self.mustar = karmbandit.mu[self.bestarm]\n",
    "\n",
    "        \n",
    "        \n",
    "        self.policy = policy\n",
    "        self.regrets = []\n",
    "        self.muhats = np.zeros(self.d)\n",
    "        \n",
    "\n",
    "        # small hack to avoid division by 0 before the arm is played for the first time\n",
    "        self.t = 1\n",
    "        self.w = np.ones(self.d) * 10**(-8)\n",
    "\n",
    "        if policy == 'epsilon-greedy':\n",
    "            self.epsilon = algoparams[0]\n",
    "        if policy == 'ucb':\n",
    "            self.c = algoparams[0]\n",
    "        if policy == 'thompson-sampling':\n",
    "            if self.distribution == 'bernoulli':\n",
    "                if prior == \"beta\":\n",
    "                    self.alphas = algoparams[:0]\n",
    "                    self.betas = algoparams[:1]\n",
    "                if prior == \"uniform\":\n",
    "                    self.alphas = np.ones(self.d)\n",
    "                    self.betas = np.ones(self.d)\n",
    "                if prior == \"gaussian\":\n",
    "                    # In the case of a gaussian prior for bernoulli distribution we assume that the prior is uniform on R\n",
    "                    # And that the bernoulli are gaussian with variance 1/4 \n",
    "                    self.mus = np.zeros(self.d)\n",
    "                    self.sigmapost = 10**-8 * np.ones(self.d)\n",
    "            if self.distribution == 'gaussian':\n",
    "                if prior == \"gaussian\":\n",
    "                    self.mushats = algoparams[:0]\n",
    "                    self.sigmapost = algoparams[:1]\n",
    "                if prior == \"uniform\":\n",
    "                    self.mushats = np.zeros(self.d)\n",
    "                    self.sigmapost = 10**8 * np.ones(self.d)\n",
    "        if policy == \"klucb\":\n",
    "            pass\n",
    "\n",
    "    def select(self):\n",
    "        \"\"\"Select the arm to pull according to the algorithm policy\n",
    "        \n",
    "        Returns:\n",
    "            index (int): index of the arm to pull\n",
    "        \"\"\"\n",
    "        if self.policy == 'ucb':\n",
    "            index = np.argmax(self.muhat + self.c * np.sqrt(np.log(self.t) / (2 * self.w)))\n",
    "        if self.policy == 'epsilon-greedy':\n",
    "            if np.random.rand() < self.epsilon:\n",
    "                index = np.random.randint(self.d)\n",
    "            else:\n",
    "                index = np.argmax(self.muhats)\n",
    "        if self.policy == 'thompson-sampling':\n",
    "            if self.prior == 'bernoulli' or self.prior == 'uniform':\n",
    "                index = np.argmax(np.random.beta(self.alphas, self.betas))\n",
    "            if self.prior == 'gaussian':\n",
    "                index = np.argmax(np.random.normal(self.muhats, self.sigmapost))\n",
    "\n",
    "        if self.policy == \"klucb\":\n",
    "            pass\n",
    "        return index\n",
    "\n",
    "    def update(self, index, reward):\n",
    "        \"\"\"Update the policy\n",
    "        \n",
    "        Args:\n",
    "            index (int): index of the arm to pull\n",
    "            reward (float): reward of the arm\n",
    "        \"\"\"\n",
    "        self.t += 1\n",
    "\n",
    "        \n",
    "        if self.w[index] < 0.5:\n",
    "            # correct the hack to avoid division by 0\n",
    "            self.w[index] = 1\n",
    "        else:\n",
    "            self.w[index] += 1\n",
    "\n",
    "        if self.policy == 'thompson-sampling':\n",
    "            if self.distribution == 'bernoulli':\n",
    "                if self.prior == 'beta' or self.prior == 'uniform':\n",
    "                    self.alphas[index] += reward\n",
    "                    self.betas[index] += 1 - reward\n",
    "                if self.prior == 'gaussian':\n",
    "                    self.muhats[index] = (self.muhats[index] * (self.w[index] - 1) + reward) / self.w[index] \n",
    "                    # I already verified the above formula\n",
    "                    if self.sigmapost[index] == 10**8:\n",
    "                        self.sigmapost[index] = 1/4\n",
    "                    else:\n",
    "                        self.sigmapost[index] = (1/self.sigmapost[index] + 1/4)**-1\n",
    "                    \n",
    "\n",
    "            if self.distribution == 'gaussian':\n",
    "                if self.prior == 'uniform':\n",
    "                    self.muhats[index] = (self.muhats[index] * (self.w[index] - 1) + reward) / self.w[index]\n",
    "                    if self.sigmapost[index] == 10**8:\n",
    "                        self.sigmapost[index] = self.sigmas[index]\n",
    "                    else:\n",
    "                        self.sigmapost[index] = (1/self.sigmapost[index] + 1/self.sigmas[index])**-1\n",
    "                if self.prior == 'gaussian':\n",
    "                    self.sigmapost[index] = (1/self.sigmapost[index] + 1/self.sigmas[index])**-1\n",
    "                    self.muhats = self.sigmapost[index] * (self.muhats[index] / self.sigmapost[index] + reward / self.sigmas[index])\n",
    "                    # The above formula is verified\n",
    "\n",
    "\n",
    "        if self.policy == \"ucb\":\n",
    "            self.muhats[index] = (self.muhats[index] * (self.w[index] - 1) + reward) / self.w[index]\n",
    "\n",
    "        self.regrets.append(self.mustar - self.mus[index])\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
